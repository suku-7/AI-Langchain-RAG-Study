{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24026960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai)\n",
      "  Using cached langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai)\n",
      "  Using cached openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached langsmith-0.4.42-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ryumo\\projects\\ai-langchain-rag\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached orjson-3.11.4-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached jiter-0.12.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Using cached regex-2025.11.3-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryumo\\projects\\ai-langchain-rag\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Using cached langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
      "Using cached langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.4.42-py3-none-any.whl (401 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.12.0-cp313-cp313-win_amd64.whl (204 kB)\n",
      "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.11.4-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Using cached regex-2025.11.3-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, pyyaml, python-dotenv, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langchain-core, langchain-openai\n",
      "\n",
      "   - --------------------------------------  1/32 [urllib3]\n",
      "   - --------------------------------------  1/32 [urllib3]\n",
      "   - --------------------------------------  1/32 [urllib3]\n",
      "   - --------------------------------------  1/32 [urllib3]\n",
      "   --- ------------------------------------  3/32 [tqdm]\n",
      "   --- ------------------------------------  3/32 [tqdm]\n",
      "   ----- ----------------------------------  4/32 [tenacity]\n",
      "   ------- --------------------------------  6/32 [regex]\n",
      "   -------- -------------------------------  7/32 [pyyaml]\n",
      "   -------- -------------------------------  7/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [python-dotenv]\n",
      "   ------------- -------------------------- 11/32 [jiter]\n",
      "   ---------------- ----------------------- 13/32 [h11]\n",
      "   ---------------- ----------------------- 13/32 [h11]\n",
      "   ----------------- ---------------------- 14/32 [distro]\n",
      "   ------------------ --------------------- 15/32 [charset_normalizer]\n",
      "   -------------------- ------------------- 16/32 [certifi]\n",
      "   ----------------------- ---------------- 19/32 [requests]\n",
      "   ------------------------- -------------- 20/32 [pydantic-core]\n",
      "   --------------------------- ------------ 22/32 [httpcore]\n",
      "   --------------------------- ------------ 22/32 [httpcore]\n",
      "   --------------------------- ------------ 22/32 [httpcore]\n",
      "   --------------------------- ------------ 22/32 [httpcore]\n",
      "   ---------------------------- ----------- 23/32 [anyio]\n",
      "   ---------------------------- ----------- 23/32 [anyio]\n",
      "   ---------------------------- ----------- 23/32 [anyio]\n",
      "   ------------------------------ --------- 24/32 [tiktoken]\n",
      "   ------------------------------- -------- 25/32 [requests-toolbelt]\n",
      "   ------------------------------- -------- 25/32 [requests-toolbelt]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   -------------------------------- ------- 26/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [httpx]\n",
      "   --------------------------------- ------ 27/32 [httpx]\n",
      "   --------------------------------- ------ 27/32 [httpx]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ----------------------------------- ---- 28/32 [openai]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------ --- 29/32 [langsmith]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   ------------------------------------- -- 30/32 [langchain-core]\n",
      "   -------------------------------------- - 31/32 [langchain-openai]\n",
      "   -------------------------------------- - 31/32 [langchain-openai]\n",
      "   ---------------------------------------- 32/32 [langchain-openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.10.5 charset_normalizer-3.4.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-1.0.4 langchain-openai-1.0.2 langsmith-0.4.42 openai-2.7.1 orjson-3.11.4 pydantic-2.12.4 pydantic-core-2.41.5 python-dotenv-1.2.1 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09f76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612aca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01f8d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인프런의 RAG, Agent 강의 중에서 최고의 인기를 갖고 있는 강의는 \"RAG(Reinforcement Learning with Augmented Data)\" 강의입니다. 이 강의는 다양한 첨단 기술을 활용하여 복잡한 문제를 해결하는 방법을 알려주며 많은 사람들에게 관심을 받고 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 42, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CaG0I5itjNtYzvvAM4SV0Qm9GSrJU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9ee11bc2-df28-4daa-a6ef-c50a3a2a7cfe-0', usage_metadata={'input_tokens': 42, 'output_tokens': 109, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"인프런의 RAG, Agent 강의는 어느 사람의 강의가 가장 인기가 많아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
